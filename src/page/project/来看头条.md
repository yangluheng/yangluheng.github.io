---
lang: zh-CN
title: 来看头条
order: 1
description: 项目
---

## 1.项目介绍

**开发技术**：Spring Cloud + Spring Boot + MybatisPlus + Redis + MySQL + Mongodb + Zookeeper + kafka + ElasticSearch + Docker + 第三方技术阿里云OSS;

**项目背景：**”来看头条“ 项目类似于今日头条，是一个新闻资讯类项目。该项目由用户端和自媒体端组成。在用户端，实现了用户通过app端登录功能、浏览文章功能、搜索文章功能、用户历史记录功能。在自媒体端，实现了自媒体管理员登录功能、发布文章功能、删除文章功能、上传素材功能、文章内容审核功能

**项目重难点：**网关搭建；文章详情静态化及存储；文章自动审核及延迟发布；分布式锁解决集群下的方法抢占执行；热点文章实时计算

**技术栈的具体应用**：

- Spring-Cloud-Gateway : 微服务之前架设的网关服务，实现服务注册中的API请求路由，以及控制流速控制和熔断处理都是常用的架构手段，而这些功能Gateway天然支持
- 运用Spring Boot快速开发框架，构建项目工程；并结合Spring Cloud全家桶技术，实现app后端、自媒体等微服务。
- 运用Spring Cloud Alibaba Nacos作为项目中的注册中心和配置中心
- 运用mybatis-plus作为持久层提升开发效率
- 采用kafka作为消息服务中间件，把自媒体文章上下架放进消息队列；通过用户的行为（点赞、评论、喜欢）实时记录用户数据，通过kafkaStream流式计算最新的数据；与客户端系统消息通知
- 运用Redis缓存技术，实现热数据的计算，提升系统性能指标，同时作为消息中间件异步消费任务。
- 使用Mysql存储用户数据，以保证上层数据查询的高性能
- 使用Mongo存储用户历史记录数据，以保证用户热数据高扩展和高性能指标 
- 运用AI技术，来完成系统自动化功能，以提升效率及节省成本。比如文章审核

 

## 2.优化

### 2.1优化一

缺陷 ：写操作（定时刷新）比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 。

解决办法：

- 数据库和缓存数据强一致场景 ：更新 db 的时候同样更新 cache，不过我们需要加一个分布式锁来保证更新 cache 的时候不存在线程安全问题。



### 2.2优化二

缺陷：消费者丢失消息的情况

我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。

当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

**解决办法**:

- 我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。 但是这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。



### 2.3优化三

存储技术选型优化：

MinIO：

AliyunOSS：



### 2.4优化四

缺陷：对于变量存在多线程并发竞争

**解决办法：**

为变量设置ThreadLocal。 



### 2.5身份验证怎么做的？

```
AuthorizedFilter + AppJwtUtil
```

1. 用户向服务器发送用户名、密码以及验证码用于登陆系统。用户进入网关开始登陆，网关过滤器进行判断，如果是登录，则路由到后台管理微服务进行登录。
2. 如果用户用户名、密码以及验证码校验正确的话，服务端会返回已经签名的 Token，也就是 JWT。
3. 用户以后每次向后端发请求都在 Header 中带上这个 JWT ，再次进入网关开始访问，网关过滤器接收用户携带的TOKEN。
4. 服务端检查 JWT 并从中获取用户相关信息。网关过滤器解析TOKEN ，判断是否有权限，如果有，则放行，如果没有则返回未认证错误。

两点建议：

1. 建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。
2. 请求服务端并携带 JWT 的常见做法是将其放在 HTTP Header 的 `Authorization` 字段中（`Authorization: Bearer Token`）。



**乐观锁：**

使用版本号。



### 2.6网关搭建：

思路分析：

1. 用户进入网关开始登陆，网关过滤器进行判断，如果是登录，则路由到后台管理微服务进行登录
2. 用户登录成功，后台管理微服务签发JWT TOKEN信息返回给用户
3. 用户再次进入网关开始访问，网关过滤器接收用户携带的TOKEN 
4. 网关过滤器解析TOKEN ，判断是否有权限，如果有，则放行，如果没有则返回未认证错误

具体实现：

第一：

​	在认证过滤器中需要用到jwt的解析，所以需要把工具类拷贝一份到网关微服务

第二：

​	在网关微服务中新建全局过滤器



### 2.7文章详情静态化及存储：

**文章详情静态化：**

​	FreeMarker 是一款模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本(HTML网页，电子邮件，配置文件，源代码等)的通用工具。 它不是面向最终用户的，而是一个Java类库，是一款程序员可以嵌入他们所开发产品的组件。

​	模板编写为FreeMarker Template Language (FTL)。它是简单的，专用的语言， 不是像PHP那样成熟的编程语言。 那就意味着要准备数据在真实编程语言中来显示，比如数据库查询和业务运算， 之后模板显示已经准备好的数据。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。 

**存储：AliyunOSS**

对象存储可提供更好的数据保护，加密、保护敏感数据。

![](http://www.img.youngxy.top/Java/fig/image-20210602180856833.png)

### 2.8文章自动审核及延迟发布：

**文章自动审核：**

1 自媒体端发布文章后，开始审核文章（异步线程的方式审核文章，在自动审核的方法上加上@Async注解（标明要异步调用），在自媒体引导类中使用@EnableAsync注解开启异步调用）

2 审核的主要是审核文章的内容（文本内容和图片）

3 借助第三方提供的接口审核文本

4 借助第三方提供的接口审核图片，由于图片存储到OSS中，需要先下载才能审核

5 如果审核失败，则需要修改自媒体文章的状态，status:2  审核失败    status:3  转到人工审核

6 如果审核成功，则需要在文章微服务中创建app端需要的文章：

​		在文章审核成功以后需要在app的article库中新增文章数据：

- ​			保存文章信息 ap_article

- ​			保存文章配置信息 ap_article_config
- ​			保存文章内容 ap_article_content



![](http://www.img.youngxy.top/Java/fig/image-20210505010938575.png)



**延迟发布：**

redis实现：zset数据类型的去重有序（分数排序）特点进行延迟。例如：时间戳作为score进行排序

实现思路：

![](http://www.img.youngxy.top/Java/fig/image-20210513150440342.png)



**问题思路：**

**1.为什么任务需要存储在数据库中？**

延迟任务是一个通用的服务，任何需要延迟得任务都可以调用该服务，需要考虑数据持久化的问题，存储数据库中是一种数据安全的考虑。

**2.为什么redis中使用两种数据类型，list和zset？**

效率问题，算法的时间复杂度

**3.在添加zset数据的时候，为什么不需要预加载？**

任务模块是一个通用的模块，项目中任何需要延迟队列的地方，都可以调用这个接口，要考虑到数据量的问题，如果数据量特别大，为了防止阻塞，只需要把未来几分钟要执行的数据存入缓存即可。

**实现：**

- 延迟队列服务提供对外接口：提供远程的feign接口
- 发布文章集成添加延迟队列接口
- 修改发布文章代码：把之前的异步调用修改为调用延迟任务
- 消费任务进行审核文章

**4.为什么选用redis作为消息队列？**

把 Redis 当作队列来使用时，会面临的 2 个问题：

- Redis 本身可能会丢数据；
- 面对消息挤压，内存资源会紧张；

所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：

- 如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。

- 如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。

  

### 2.9分布式锁解决集群下的方法抢占执行：

**问题描述：**

启动两台heima-leadnews-schedule服务，每台服务都会去执行refresh定时任务方法

**分布式锁：**

控制分布式系统有序的去对共享资源进行操作，通过互斥来保证数据的一致性。

**解决方案：**

sexnx （SET if Not eXists） 命令在指定的 key 不存在时，为 key 设置指定的值。

这种加锁的思路是，如果 key 不存在则为 key 设置 value，如果 key 已存在则 SETNX 命令不做任何操作

- 客户端A请求服务器设置key的值，如果设置成功就表示加锁成功
- 客户端B也去请求服务器设置key的值，如果返回失败，那么就代表加锁失败
- 客户端A执行代码完成，删除锁
- 客户端B在等待一段时间后再去请求设置key的值，设置成功
- 客户端B执行代码完成，删除锁



### 2.10热点文章实时计算：

![](http://www.img.youngxy.top/Java/fig/image-20210730201509223.png)



思路说明：

![](http://www.img.youngxy.top/Java/fig/image-20210621235620854.png)





**待优化**：

使用FastDFS作为静态资源存储器，在其上实现热静态资源缓存、淘汰等功能（待优化）

运用Hbase技术，存储系统中的冷数据，保证系统数据的可靠性（待优化）

运用ES搜索技术，对冷数据、文章数据建立索引，以保证冷数据、文章查询性能（待优化）

当用户 Logout 的话，JWT 也还有效。除非，我们在后端增加额外的处理逻辑比如将失效的 JWT 存储起来，后端先验证 JWT 是否有效再进行处理。

## 3.QPS估算方法、性能测试：

**QPS（Query Per Second）：每秒请求数，就是说服务器在一秒的时间内处理了多少个请求。**

怎么估出每秒钟能处理多少请求呢？

**方式一:自己在接口里记录**

这种方式指的是在你的接口里，日志记录了能体现该接口特性的，并具有唯一性的字符串！

例如，下面这一段代码：

```java
@RestController 
@RequestMapping("/home") 
public class IndexController {
 //省略
 @RequestMapping("/index") 
 String index() { 
 logger.info("渣渣烟");
 return "index"; 
 } 
} 
```

假设现在我要统计index这个接口的QPS！

OK，什么叫能体现该接口特性的字符串呢！就像上面的"渣渣烟"这个字符串，只在index这个接口里出现过，没在其他其他接口里出现过！因此，只要统计出"渣渣烟"这个字符串在日志里的出现次数，就能知道该接口的请求次数！

什么叫具有唯一性的字符串呢！所谓唯一性，指的是"渣渣烟"这个字符串，在这个接口的一次调用流程中，只出现一次！如果出现两次，就会导致到时候统计出来的次数会多一倍，所以尽量选择具有唯一性的字段！

**方式二:利用tomcat的access log**

tomcat自带的access log功能：

```
server.tomcat.accesslog.directory
设定log的目录，默认: logs
server.tomcat.accesslog.enabled
是否开启access log，默认: false
```

此时，你访问一次/home/index地址，会有下面这样日志：

```
127.0.0.1 - - [xxx] "POST /home/index HTTP/1.1" 200 138
```

执行一串命令：

```shell
cat xx.log |grep 'GET /mvc2'|cut -d ' ' -f4|uniq -c|sort -n -r 
```

**JMeter测试：**

![](http://www.img.youngxy.top/Java/fig/%E9%A1%B9%E7%9B%AE%E6%B5%8B%E8%AF%95.PNG)



## **自我介绍：**

面试官，您好，首先很感谢您给我的面试机会！我叫杨路恒，今年24岁，山东济宁人，就读于陕西师范大学，今年研二，软件工程专业，研究方向为知识图谱。大学时间我主要利用课外时间学习了 Java 以及 一些框架 。在校期间参与了全国大学生数学建模竞赛和全国大学生英语竞赛，并且在数学建模比赛中担任队长并获得了陕西省一等奖。说到业余爱好的话，一个是比较喜欢通过博客整理分享自己所学知识，现在在CSDN上的粉丝数达到了3k+，访问量达到了44W+。 另一个是喜欢旅游和骑行的方式来放松。这就是我的自我介绍，感谢。 

