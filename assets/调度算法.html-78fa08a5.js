import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as l,o as n,c,a as e,e as o,d as i,f as t}from"./app-3ec5641f.js";const s={},d=t('<h2 id="七-操作系统" tabindex="-1"><a class="header-anchor" href="#七-操作系统" aria-hidden="true">#</a> 七：操作系统</h2><h3 id="进程和线程管理" tabindex="-1"><a class="header-anchor" href="#进程和线程管理" aria-hidden="true">#</a> 进程和线程管理</h3><h4 id="java里的进程有哪些状态" tabindex="-1"><a class="header-anchor" href="#java里的进程有哪些状态" aria-hidden="true">#</a> Java里的进程有哪些状态？</h4><ul><li><p>新建状态(New)：新创建了一个线程对象。</p></li><li><p>就绪状态(Runnable)：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于“可运行线程池”中，变得可运行，只等待获取CPU的使用权。即在就绪状态的进程除CPU之外，其它的运行所需资源都已全部获得。</p></li><li><p>运行状态(Running)：就绪状态的线程获取了CPU，执行程序代码。</p></li><li><p>阻塞状态(Blocked)：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：</p></li><li><p>等待阻塞：运行的线程执行wait()方法，该线程会释放占用的所有资源，JVM会把该线程放入“等待池”中。进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或notifyAll()方法才能被唤醒， 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入“锁池”中。 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。</p></li><li><p>终止状态(Dead)：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。 <img src="https://img-blog.csdnimg.cn/ff58fec643d74a3d974051b8538cd15b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAUmVkaHVyLQ==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述" loading="lazy"></p></li></ul><h3 id="进程间通信" tabindex="-1"><a class="header-anchor" href="#进程间通信" aria-hidden="true">#</a> 进程间通信</h3><h3 id="互斥同步" tabindex="-1"><a class="header-anchor" href="#互斥同步" aria-hidden="true">#</a> 互斥同步</h3><p>线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。</p><p>下面是几种常见的线程同步的方式：</p><ol><li><strong>互斥锁(Mutex)</strong> ：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 <code>synchronized</code> 关键词和各种 <code>Lock</code> 都是这种机制。</li><li><strong>读写锁（Read-Write Lock）</strong>：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。</li><li><strong>信号量(Semaphore)</strong> ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。</li><li><strong>屏障（Barrier）</strong> ：屏障是一种同步原语，用于等待多个线程到达某个点再一起继续执行。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都到达屏障后，它们才会一起继续执行。比如 Java 中的 <code>CyclicBarrier</code> 是这种机制。</li><li><strong>事件(Event)</strong> :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。</li></ol><p>在进程/线程并发执行的过程中，进程/线程之间存在协作的关系，例如有互斥、同步的关系。</p><p>为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p><ul><li><em>锁</em>：加锁、解锁操作；</li><li><em>信号量</em>：P、V 操作；</li></ul><p>这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步。</p><h3 id="进程间通信-1" tabindex="-1"><a class="header-anchor" href="#进程间通信-1" aria-hidden="true">#</a> 进程间通信</h3><ul><li><strong>管道/匿名管道(Pipes)</strong> ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。</li><li><strong>有名管道(Named Pipes)</strong> : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循 <strong>先进先出(First In First Out)</strong> 。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。</li><li><strong>信号(Signal)</strong> ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；</li><li><strong>消息队列(Message Queuing)</strong> ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。<strong>消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。</strong></li><li><strong>信号量(Semaphores)</strong> ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。</li><li><strong>共享内存(Shared memory)</strong> ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。</li><li><strong>套接字(Sockets)</strong> : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。</li></ul><h3 id="虚拟内存管理" tabindex="-1"><a class="header-anchor" href="#虚拟内存管理" aria-hidden="true">#</a> 虚拟内存管理</h3><h3 id="i-o-多路复用" tabindex="-1"><a class="header-anchor" href="#i-o-多路复用" aria-hidden="true">#</a> I/O 多路复用</h3><p>既然为每个请求分配一个进程/线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 <strong>I/O 多路复用</strong>技术。</p><p>一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。</p><p>我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，<strong>进程可以通过一个系统调用函数从内核中获取多个事件</strong>。</p><p>select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。</p><h5 id="epoll" tabindex="-1"><a class="header-anchor" href="#epoll" aria-hidden="true">#</a> epoll</h5><p>epoll 通过两个方面，很好解决了 select/poll 的问题。</p><p><em>第一点</em>，epoll 在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的 socket 通过 <code>epoll_ctl()</code> 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 <code>O(logn)</code>。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</p><p><em>第二点</em>， epoll 使用<strong>事件驱动</strong>的机制，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个 socket 有事件发生时，通过<strong>回调函数</strong>内核会将其加入到这个就绪事件列表中，当用户调用 <code>epoll_wait()</code> 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。</p><p>从下图你可以看到 epoll 相关的接口作用：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/操作系统/多路复用/epoll.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，<strong>epoll 被称为解决 C10K 问题的利器</strong>。</p><p>插个题外话，网上文章不少说，<code>epoll_wait</code> 返回时，对于就绪的事件，epoll 使用的是共享内存的方式，即用户态和内核态都指向了就绪链表，所以就避免了内存拷贝消耗。</p><p>这是错的！看过 epoll 内核源码的都知道，<strong>压根就没有使用共享内存这个玩意</strong>。</p><p>epoll 支持两种事件触发模式，分别是<strong>边缘触发（*edge-triggered，ET*）**和**水平触发（*level-triggered，LT*）</strong>。</p><p>这两个术语还挺抽象的，其实它们的区别还是很好理解的。</p><ul><li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li><li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</strong>，目的是告诉我们有数据需要读取；</li></ul><p>举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。</p><p>这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。</p><p>如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。</p><p>如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I/O 搭配使用</strong>，程序会一直执行 I/O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p><p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p><p>select/poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p><p>C10K ：并发 1 万请求，也就是经典的 C10K 问题 ，C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。</p>',40),p={href:"https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#%E5%A6%82%E4%BD%95%E6%9C%8D%E5%8A%A1%E6%9B%B4%E5%A4%9A%E7%9A%84%E7%94%A8%E6%88%B7",target:"_blank",rel:"noopener noreferrer"},g=t(`<h3 id="零拷贝" tabindex="-1"><a class="header-anchor" href="#零拷贝" aria-hidden="true">#</a> 零拷贝</h3><p>零拷贝技术实现的方式通常有 2 种：</p><ul><li>mmap + write</li><li>sendfile</li></ul><p>下面就谈一谈，它们是如何减少「上下文切换」和「数据拷贝」的次数。</p><h4 id="mmap-write" tabindex="-1"><a class="header-anchor" href="#mmap-write" aria-hidden="true">#</a> mmap + write</h4><p>在前面我们知道，<code>read()</code> 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 <code>mmap()</code> 替换 <code>read()</code> 系统调用函数。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>buf = mmap(file, len);
write(sockfd, buf, len);
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><code>mmap()</code> 系统调用函数会直接把内核缓冲区里的数据「<strong>映射</strong>」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/操作系统/零拷贝/mmap %2B write 零拷贝.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>具体过程如下：</p><ul><li>应用进程调用了 <code>mmap()</code> 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li><li>应用进程再调用 <code>write()</code>，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li><li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li></ul><p>我们可以得知，通过使用 <code>mmap()</code> 来代替 <code>read()</code>， 可以减少一次数据拷贝的过程。</p><p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p><h4 id="sendfile" tabindex="-1"><a class="header-anchor" href="#sendfile" aria-hidden="true">#</a> sendfile</h4><p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 <code>sendfile()</code>，函数形式如下：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>#include &lt;sys/socket.h&gt;
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p><p>首先，它可以替代前面的 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p><p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/操作系统/零拷贝/senfile-3次拷贝.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p><p>于是，从 Linux 内核 <code>2.4</code> 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， <code>sendfile()</code> 系统调用的过程发生了点变化，具体过程如下：</p><ul><li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li><li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li></ul><p>所以，这个过程之中，只进行了 2 次数据拷贝，如下图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/操作系统/零拷贝/senfile-零拷贝.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>这就是所谓的<strong>零拷贝（*Zero-copy*）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</strong>。</p><p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p><p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong>。</p><h4 id="使用零拷贝技术的项目" tabindex="-1"><a class="header-anchor" href="#使用零拷贝技术的项目" aria-hidden="true">#</a> 使用零拷贝技术的项目</h4><p>事实上，Kafka 这个开源项目，就利用了「零拷贝」技术，从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。</p><p>如果你追溯 Kafka 文件传输的代码，你会发现，最终它调用了 Java NIO 库里的 <code>transferTo</code> 方法。</p><p>如果 Linux 系统支持 <code>sendfile()</code> 系统调用，那么 <code>transferTo()</code> 实际上最后就会使用到 <code>sendfile()</code> 系统调用函数。</p><h3 id="reactor" tabindex="-1"><a class="header-anchor" href="#reactor" aria-hidden="true">#</a> Reactor</h3><p>Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p><ul><li>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；</li><li>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</li></ul><p>Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：</p><ul><li>Reactor 的数量可以只有一个，也可以有多个；</li><li>处理资源池可以是单个进程 / 线程，也可以是多个进程 /线程；</li></ul><p>将上面的两个因素排列组设一下，理论上就可以有 4 种方案选择：</p><ul><li>单 Reactor 单进程 / 线程；</li><li>单 Reactor 多进程 / 线程；</li><li>多 Reactor 单进程 / 线程；</li><li>多 Reactor 多进程 / 线程；</li></ul><p>其中，「多 Reactor 单进程 / 线程」实现方案相比「单 Reactor 单进程 / 线程」方案，不仅复杂而且也没有性能优势，因此实际中并没有应用。</p><p>剩下的 3 个方案都是比较经典的，且都有应用在实际的项目中：</p><ul><li>单 Reactor 单进程 / 线程；</li><li>单 Reactor 多线程 / 进程；</li><li>多 Reactor 多进程 / 线程；</li></ul><p>方案具体使用进程还是线程，要看使用的编程语言以及平台有关：</p><ul><li>Java 语言一般使用线程，比如 Netty;</li><li>C 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。</li></ul><p>接下来，分别介绍这三个经典的 Reactor 方案。</p><h4 id="单-reactor-单进程-线程" tabindex="-1"><a class="header-anchor" href="#单-reactor-单进程-线程" aria-hidden="true">#</a> 单 Reactor 单进程 / 线程</h4><p>一般来说，C 语言实现的是「<strong>单 Reactor 单进程</strong>」的方案，因为 C 语编写完的程序，运行后就是一个独立的进程，不需要在进程中再创建线程。</p><p>而 Java 语言实现的是「<strong>单 Reactor 单线程</strong>」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，我们写的 Java 程序只是其中的一个线程而已。</p><p>我们来看看「<strong>单 Reactor 单进程</strong>」的方案示意图：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/操作系统/Reactor/单Reactor单进程.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>可以看到进程里有 <strong>Reactor、Acceptor、Handler</strong> 这三个对象：</p><ul><li>Reactor 对象的作用是监听和分发事件；</li><li>Acceptor 对象的作用是获取连接；</li><li>Handler 对象的作用是处理业务；</li></ul><p>对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。</p><p>接下来，介绍下「单 Reactor 单进程」这个方案：</p><ul><li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li><li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li><li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li><li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li></ul><p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。</p><p>但是，这种方案存在 2 个缺点：</p><ul><li>第一个缺点，因为只有一个进程，<strong>无法充分利用 多核 CPU 的性能</strong>；</li><li>第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，<strong>如果业务处理耗时比较长，那么就造成响应的延迟</strong>；</li></ul><p>所以，单 Reactor 单进程的方案<strong>不适用计算机密集型的场景，只适用于业务处理非常快速的场景</strong>。</p><p>Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p><h4 id="单-reactor-多线程-多进程" tabindex="-1"><a class="header-anchor" href="#单-reactor-多线程-多进程" aria-hidden="true">#</a> 单 Reactor 多线程 / 多进程</h4><p>如果要克服「单 Reactor 单线程 / 进程」方案的缺点，那么就需要引入多线程 / 多进程，这样就产生了<strong>单 Reactor 多线程 / 多进程</strong>的方案。</p><p>闻其名不如看其图，先来看看「单 Reactor 多线程」方案的示意图如下：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/操作系统/Reactor/单Reactor多线程.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>详细说一下这个方案：</p><ul><li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li><li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li><li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li></ul><p>上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：</p><ul><li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；</li><li>子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；</li></ul><p>单 Reator 多线程的方案优势在于<strong>能够充分利用多核 CPU 的能力</strong>，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。</p><p>例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。</p><p>要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。</p><p>聊完单 Reactor 多线程的方案，接着来看看单 Reactor 多进程的方案。</p><p>事实上，单 Reactor 多进程相比单 Reactor 多线程实现起来很麻烦，主要因为要考虑子进程 &lt;-&gt; 父进程的双向通信，并且父进程还得知道子进程要将数据发送给哪个客户端。</p><p>而多线程间可以共享数据，虽然要额外考虑并发问题，但是这远比进程间通信的复杂度低得多，因此实际应用中也看不到单 Reactor 多进程的模式。</p><p>另外，「单 Reactor」的模式还有个问题，<strong>因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方</strong>。</p><h4 id="多-reactor-多进程-线程" tabindex="-1"><a class="header-anchor" href="#多-reactor-多进程-线程" aria-hidden="true">#</a> 多 Reactor 多进程 / 线程</h4><p>要解决「单 Reactor」的问题，就是将「单 Reactor」实现成「多 Reactor」，这样就产生了第 <strong>多 Reactor 多进程 / 线程</strong>的方案。</p><p>老规矩，闻其名不如看其图。多 Reactor 多进程 / 线程方案的示意图如下（以线程为例）：</p><figure><img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/操作系统/Reactor/主从Reactor多线程.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>方案详细说明如下：</p><ul><li>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</li><li>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。</li><li>如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。</li><li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li></ul><p>多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：</p><ul><li>主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。</li><li>主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。</li></ul>`,83),h={href:"https://www.xiaolincoding.com/os/8_network_system/reactor.html#%E6%BC%94%E8%BF%9B",target:"_blank",rel:"noopener noreferrer"};function m(u,f){const a=l("ExternalLinkIcon");return n(),c("div",null,[d,e("p",null,[o("参考："),e("a",p,[o("https://www.xiaolincoding.com/os/8_network_system/selete_poll_epoll.html#如何服务更多的用户"),i(a)])]),g,e("p",null,[o("参考："),e("a",h,[o("https://www.xiaolincoding.com/os/8_network_system/reactor.html#演进"),i(a)])])])}const _=r(s,[["render",m],["__file","调度算法.html.vue"]]);export{_ as default};
