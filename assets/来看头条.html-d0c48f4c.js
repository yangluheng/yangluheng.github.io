import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{o as a,c as e,f as p}from"./app-afa6d82a.js";const r={},t=p(`<h2 id="十二-项目" tabindex="-1"><a class="header-anchor" href="#十二-项目" aria-hidden="true">#</a> 十二：项目</h2><p><strong>开发技术</strong>：Spring Cloud + Spring Boot + MybatisPlus + Redis + mysql + Mongodb + Zookeeper + kafka + ElasticSearch + Docker + 第三方技术阿里云OSS;</p><p><strong>项目背景：</strong>”来看头条“ 项目类似于今日头条，是一个新闻资讯类项目。该项目由用户端和自媒体端组成。在用户端，实现了用户通过app端登录功能、浏览文章功能、搜索文章功能、用户历史记录功能。在自媒体端，实现了自媒体管理员登录功能、发布文章功能、删除文章功能、上传素材功能、文章内容审核功能</p><p>**项目重难点：**网关搭建；文章详情静态化及存储；文章自动审核及延迟发布；分布式锁解决集群下的方法抢占执行；热点文章实时计算</p><p><strong>技术栈的具体应用</strong>：</p><ul><li>Spring-Cloud-Gateway : 微服务之前架设的网关服务，实现服务注册中的API请求路由，以及控制流速控制和熔断处理都是常用的架构手段，而这些功能Gateway天然支持</li><li>运用Spring Boot快速开发框架，构建项目工程；并结合Spring Cloud全家桶技术，实现app后端、自媒体等微服务。</li><li>运用Spring Cloud Alibaba Nacos作为项目中的注册中心和配置中心</li><li>运用mybatis-plus作为持久层提升开发效率</li><li>采用kafka作为消息服务中间件，把自媒体文章上下架放进消息队列；通过用户的行为（点赞、评论、喜欢）实时记录用户数据，通过kafkaStream流式计算最新的数据；与客户端系统消息通知</li><li>运用Redis缓存技术，实现热数据的计算，提升系统性能指标，同时作为消息中间件异步消费任务。</li><li>使用Mysql存储用户数据，以保证上层数据查询的高性能</li><li>使用Mongo存储用户历史记录数据，以保证用户热数据高扩展和高性能指标</li><li>运用AI技术，来完成系统自动化功能，以提升效率及节省成本。比如文章审核</li></ul><h4 id="优化" tabindex="-1"><a class="header-anchor" href="#优化" aria-hidden="true">#</a> <strong>优化：</strong></h4><h5 id="_1-优化一" tabindex="-1"><a class="header-anchor" href="#_1-优化一" aria-hidden="true">#</a> （1）优化一</h5><p>缺陷 ：写操作（定时刷新）比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 。</p><p>解决办法：</p><ul><li>数据库和缓存数据强一致场景 ：更新 db 的时候同样更新 cache，不过我们需要加一个分布式锁来保证更新 cache 的时候不存在线程安全问题。</li></ul><h5 id="_2-优化二" tabindex="-1"><a class="header-anchor" href="#_2-优化二" aria-hidden="true">#</a> （2）优化二</h5><p>缺陷：消费者丢失消息的情况</p><p>我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。</p><p>当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。</p><p><strong>解决办法</strong>:</p><ul><li>我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。 细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。</li></ul><h5 id="_3-优化三" tabindex="-1"><a class="header-anchor" href="#_3-优化三" aria-hidden="true">#</a> （3）优化三</h5><p>存储技术选型优化：</p><p>MinIO：</p><p>AliyunOSS：</p><h5 id="_4-优化四" tabindex="-1"><a class="header-anchor" href="#_4-优化四" aria-hidden="true">#</a> （4）优化四</h5><p>缺陷：对于变量存在多线程并发竞争</p><p><strong>解决办法：</strong></p><p>为变量设置ThreadLocal。</p><h4 id="身份验证怎么做的" tabindex="-1"><a class="header-anchor" href="#身份验证怎么做的" aria-hidden="true">#</a> <strong>身份验证怎么做的？</strong></h4><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>AuthorizedFilter + AppJwtUtil
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ol><li>用户向服务器发送用户名、密码以及验证码用于登陆系统。用户进入网关开始登陆，网关过滤器进行判断，如果是登录，则路由到后台管理微服务进行登录。</li><li>如果用户用户名、密码以及验证码校验正确的话，服务端会返回已经签名的 Token，也就是 JWT。</li><li>用户以后每次向后端发请求都在 Header 中带上这个 JWT ，再次进入网关开始访问，网关过滤器接收用户携带的TOKEN。</li><li>服务端检查 JWT 并从中获取用户相关信息。网关过滤器解析TOKEN ，判断是否有权限，如果有，则放行，如果没有则返回未认证错误。</li></ol><p>两点建议：</p><ol><li>建议将 JWT 存放在 localStorage 中，放在 Cookie 中会有 CSRF 风险。</li><li>请求服务端并携带 JWT 的常见做法是将其放在 HTTP Header 的 <code>Authorization</code> 字段中（<code>Authorization: Bearer Token</code>）。</li></ol><p><strong>乐观锁：</strong></p><p>使用版本号。</p><h4 id="网关搭建" tabindex="-1"><a class="header-anchor" href="#网关搭建" aria-hidden="true">#</a> <strong>网关搭建</strong>：</h4><p>思路分析：</p><ol><li>用户进入网关开始登陆，网关过滤器进行判断，如果是登录，则路由到后台管理微服务进行登录</li><li>用户登录成功，后台管理微服务签发JWT TOKEN信息返回给用户</li><li>用户再次进入网关开始访问，网关过滤器接收用户携带的TOKEN</li><li>网关过滤器解析TOKEN ，判断是否有权限，如果有，则放行，如果没有则返回未认证错误</li></ol><p>具体实现：</p><p>第一：</p><p>​ 在认证过滤器中需要用到jwt的解析，所以需要把工具类拷贝一份到网关微服务</p><p>第二：</p><p>​ 在网关微服务中新建全局过滤器</p><h4 id="文章详情静态化及存储" tabindex="-1"><a class="header-anchor" href="#文章详情静态化及存储" aria-hidden="true">#</a> 文章详情静态化及存储：</h4><p><strong>文章详情静态化：</strong></p><p>​ FreeMarker 是一款模板引擎： 即一种基于模板和要改变的数据， 并用来生成输出文本(HTML网页，电子邮件，配置文件，源代码等)的通用工具。 它不是面向最终用户的，而是一个Java类库，是一款程序员可以嵌入他们所开发产品的组件。</p><p>​ 模板编写为FreeMarker Template Language (FTL)。它是简单的，专用的语言， 不是像PHP那样成熟的编程语言。 那就意味着要准备数据在真实编程语言中来显示，比如数据库查询和业务运算， 之后模板显示已经准备好的数据。在模板中，你可以专注于如何展现数据， 而在模板之外可以专注于要展示什么数据。</p><p><strong>存储：AliyunOSS</strong></p><p>对象存储可提供更好的数据保护，加密、保护敏感数据。</p><figure><img src="http://www.img.youngxy.top/Java/fig/image-20210602180856833.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h4 id="文章自动审核及延迟发布" tabindex="-1"><a class="header-anchor" href="#文章自动审核及延迟发布" aria-hidden="true">#</a> 文章自动审核及延迟发布：</h4><p><strong>文章自动审核：</strong></p><p>1 自媒体端发布文章后，开始审核文章（异步线程的方式审核文章，在自动审核的方法上加上@Async注解（标明要异步调用），在自媒体引导类中使用@EnableAsync注解开启异步调用）</p><p>2 审核的主要是审核文章的内容（文本内容和图片）</p><p>3 借助第三方提供的接口审核文本</p><p>4 借助第三方提供的接口审核图片，由于图片存储到OSS中，需要先下载才能审核</p><p>5 如果审核失败，则需要修改自媒体文章的状态，status:2 审核失败 status:3 转到人工审核</p><p>6 如果审核成功，则需要在文章微服务中创建app端需要的文章：</p><p>​ 在文章审核成功以后需要在app的article库中新增文章数据：</p><ul><li><p>​ 保存文章信息 ap_article</p></li><li><p>​ 保存文章配置信息 ap_article_config</p></li><li><p>​ 保存文章内容 ap_article_content</p></li></ul><figure><img src="http://www.img.youngxy.top/Java/fig/image-20210505010938575.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>延迟发布：</strong></p><p>redis实现：zset数据类型的去重有序（分数排序）特点进行延迟。例如：时间戳作为score进行排序</p><p>实现思路：</p><figure><img src="http://www.img.youngxy.top/Java/fig/image-20210513150440342.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>问题思路：</p><p>1.为什么任务需要存储在数据库中？</p><p>延迟任务是一个通用的服务，任何需要延迟得任务都可以调用该服务，需要考虑数据持久化的问题，存储数据库中是一种数据安全的考虑。</p><p>2.为什么redis中使用两种数据类型，list和zset？</p><p>效率问题，算法的时间复杂度</p><p>3.在添加zset数据的时候，为什么不需要预加载？</p><p>任务模块是一个通用的模块，项目中任何需要延迟队列的地方，都可以调用这个接口，要考虑到数据量的问题，如果数据量特别大，为了防止阻塞，只需要把未来几分钟要执行的数据存入缓存即可。</p><p>实现：</p><ul><li>延迟队列服务提供对外接口：提供远程的feign接口</li><li>发布文章集成添加延迟队列接口</li><li>修改发布文章代码：把之前的异步调用修改为调用延迟任务</li><li>消费任务进行审核文章</li></ul><p>4.为什么选用redis作为消息队列？</p><p>把 Redis 当作队列来使用时，会面临的 2 个问题：</p><ul><li>Redis 本身可能会丢数据；</li><li>面对消息挤压，内存资源会紧张；</li></ul><p>所以，能不能将 Redis 作为消息队列来使用，关键看你的业务场景：</p><ul><li><p>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</p></li><li><p>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</p></li></ul><h4 id="分布式锁解决集群下的方法抢占执行" tabindex="-1"><a class="header-anchor" href="#分布式锁解决集群下的方法抢占执行" aria-hidden="true">#</a> 分布式锁解决集群下的方法抢占执行：</h4><p>问题描述：</p><p>启动两台heima-leadnews-schedule服务，每台服务都会去执行refresh定时任务方法</p><p>分布式锁：</p><p>控制分布式系统有序的去对共享资源进行操作，通过互斥来保证数据的一致性。</p><p>解决方案：</p><p>sexnx （SET if Not eXists） 命令在指定的 key 不存在时，为 key 设置指定的值。</p><p>这种加锁的思路是，如果 key 不存在则为 key 设置 value，如果 key 已存在则 SETNX 命令不做任何操作</p><ul><li>客户端A请求服务器设置key的值，如果设置成功就表示加锁成功</li><li>客户端B也去请求服务器设置key的值，如果返回失败，那么就代表加锁失败</li><li>客户端A执行代码完成，删除锁</li><li>客户端B在等待一段时间后再去请求设置key的值，设置成功</li><li>客户端B执行代码完成，删除锁</li></ul><h4 id="热点文章实时计算" tabindex="-1"><a class="header-anchor" href="#热点文章实时计算" aria-hidden="true">#</a> 热点文章实时计算：</h4><figure><img src="http://www.img.youngxy.top/Java/fig/image-20210730201509223.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>思路说明：</p><figure><img src="http://www.img.youngxy.top/Java/fig/image-20210621235620854.png" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p><strong>待优化</strong>：</p><p>使用FastDFS作为静态资源存储器，在其上实现热静态资源缓存、淘汰等功能（待优化）</p><p>运用Hbase技术，存储系统中的冷数据，保证系统数据的可靠性（待优化）</p><p>运用ES搜索技术，对冷数据、文章数据建立索引，以保证冷数据、文章查询性能（待优化）</p><p>当用户 Logout 的话，JWT 也还有效。除非，我们在后端增加额外的处理逻辑比如将失效的 JWT 存储起来，后端先验证 JWT 是否有效再进行处理。</p><h2 id="自我介绍" tabindex="-1"><a class="header-anchor" href="#自我介绍" aria-hidden="true">#</a> <strong>自我介绍：</strong></h2><p>面试官，您好，首先很感谢您给我的面试机会！我叫杨路恒，今年24岁，山东济宁人，就读于陕西师范大学，今年研二，软件工程专业，研究方向为知识图谱。大学时间我主要利用课外时间学习了 Java 以及 一些框架 。在校期间参与了全国大学生数学建模竞赛和全国大学生英语竞赛，并且在数学建模比赛中担任队长并获得了陕西省一等奖。说到业余爱好的话，一个是比较喜欢通过博客整理分享自己所学知识，现在在CSDN上的粉丝数达到了3k+，访问量达到了44W+。 另一个是喜欢旅游和骑行的方式来放松。这就是我的自我介绍，感谢。</p>`,96),l=[t];function n(o,s){return a(),e("div",null,l)}const h=i(r,[["render",n],["__file","来看头条.html.vue"]]);export{h as default};
